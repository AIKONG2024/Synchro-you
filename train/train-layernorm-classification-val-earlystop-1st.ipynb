{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9739372,"sourceType":"datasetVersion","datasetId":5961287},{"sourceId":9741204,"sourceType":"datasetVersion","datasetId":5962620}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import StepLR\n\nimport numpy as np\nimport random\n\nfrom copy import deepcopy","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-29T04:46:51.728981Z","iopub.execute_input":"2024-10-29T04:46:51.729562Z","iopub.status.idle":"2024-10-29T04:46:56.166757Z","shell.execute_reply.started":"2024-10-29T04:46:51.729523Z","shell.execute_reply":"2024-10-29T04:46:56.165752Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \nseed_everything(12)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T04:46:56.168930Z","iopub.execute_input":"2024-10-29T04:46:56.169368Z","iopub.status.idle":"2024-10-29T04:46:56.180400Z","shell.execute_reply.started":"2024-10-29T04:46:56.169322Z","shell.execute_reply":"2024-10-29T04:46:56.179605Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class skeleton_LSTM(nn.Module):\n    def __init__(self, feature_dim, output_dim):\n        super(skeleton_LSTM, self).__init__()\n        \n        self.feature_dim = feature_dim\n        self.output_dim = output_dim\n        \n        self.lstm1 = nn.LSTM(input_size=self.feature_dim, hidden_size=128, num_layers=1, batch_first=True)\n        self.layer_norm1 = nn.LayerNorm(128)\n        \n        self.lstm2 = nn.LSTM(input_size=128, hidden_size=256, num_layers=1, batch_first=True)\n        self.layer_norm2 = nn.LayerNorm(256)\n        \n        self.lstm3 = nn.LSTM(input_size=256, hidden_size=512, num_layers=1, batch_first=True)\n        self.layer_norm3 = nn.LayerNorm(512)\n        \n        self.fc1 = nn.Linear(512,256)\n        self.fc2 = nn.Linear(256,output_dim)\n        \n    def forward(self, x):\n        x, _ = self.lstm1(x)\n        x = self.layer_norm1(x)\n        \n        x, _ = self.lstm2(x)\n        x = self.layer_norm2(x)\n        \n        x, (hn, cn) = self.lstm3(x)\n        x = self.layer_norm3(x)\n        \n        x = F.relu(self.fc1(x[:,-1,:]))\n        embedding = self.fc2(x)\n        \n        return embedding\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T04:46:56.181990Z","iopub.execute_input":"2024-10-29T04:46:56.182556Z","iopub.status.idle":"2024-10-29T04:46:56.193538Z","shell.execute_reply.started":"2024-10-29T04:46:56.182508Z","shell.execute_reply":"2024-10-29T04:46:56.192605Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class head(nn.Module) :\n    def __init__(self):\n        super(head, self).__init__()\n        \n        # Feedforward layers\n        self.fc1 = nn.Linear(64, 32)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(32, 1)  # Output layer has 1 unit for binary classification\n        self.sigmoid = nn.Sigmoid()  # Sigmoid for probability output\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        x = self.sigmoid(x)\n        return x\n\n    ","metadata":{"execution":{"iopub.status.busy":"2024-10-29T04:46:56.196040Z","iopub.execute_input":"2024-10-29T04:46:56.196348Z","iopub.status.idle":"2024-10-29T04:46:56.204710Z","shell.execute_reply.started":"2024-10-29T04:46:56.196299Z","shell.execute_reply":"2024-10-29T04:46:56.203804Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset\n\nangle = [['left_biceps', 'left_forearm'],\n         ['right_biceps', 'right_forearm'],\n         ['between_shoulders', 'left_body'],\n         ['between_shoulders', 'right_body'],\n         ['between_shoulders', 'rigth_neck'],\n         ['between_shoulders', 'left_neck'],\n         ['between_pelvis','left_thigh'],\n         ['between_pelvis','right_thigh'],\n         ['right_thigh','right_calf'],\n         ['left_thigh','left_calf'],\n         ['right_body','right_thigh'],\n         ['left_body','left_thigh']\n        ]\n         \n\nbody_parts = {'left_biceps': [11, 13],\n              'left_forearm': [13, 15],\n              'right_biceps': [12, 14],\n              'right_forearm': [14, 16],\n              'between_shoulders': [11, 12],\n              'left_body': [11, 23],\n              'right_body': [12, 24],\n              'between_pelvis': [23, 24],\n              'left_thigh': [23, 25],\n              'left_calf': [25, 27],\n              'right_thigh': [24, 26],\n              'right_calf': [26, 28],\n              'left_neck': [9, 11],\n              'rigth_neck': [10, 12]}\n\n\ndef calculate_angles(matrix1, matrix2):\n    dot_product = np.einsum('ij,ij->i', matrix1, matrix2)\n    norm1 = np.linalg.norm(matrix1, axis=1)\n    norm2 = np.linalg.norm(matrix2, axis=1)\n    cos_theta = dot_product / (norm1 * norm2)\n    angles = np.arccos(np.clip(cos_theta, -1.0, 1.0))\n    return angles\n\n\ndef make_df_angle(path):\n    df = pd.read_csv(path)\n    df_angle = pd.DataFrame()\n\n    for body_parts1, body_parts2 in angle:\n        body_parts1_vec = body_parts[body_parts1]\n        body_parts2_vec = body_parts[body_parts2]\n\n        # 벡터 계산\n        vec_mat1 = df.iloc[:, body_parts1_vec[0]*3+1:body_parts1_vec[0]*3+4].values - df.iloc[:, body_parts1_vec[1]*3+1:body_parts1_vec[1]*3+4].values\n        vec_mat2 = df.iloc[:, body_parts2_vec[0]*3+1:body_parts2_vec[0]*3+4].values - df.iloc[:, body_parts2_vec[1]*3+1:body_parts2_vec[1]*3+4].values\n\n        angles = calculate_angles(vec_mat1, vec_mat2)\n        df_angle[f'{body_parts1}_{body_parts2}'] = angles\n        \n    df_angle = df_angle.replace([np.inf, -np.inf], 0.0)\n    df_angle = df_angle.fillna(0.0)\n\n\n    return df_angle\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T04:46:56.206215Z","iopub.execute_input":"2024-10-29T04:46:56.206648Z","iopub.status.idle":"2024-10-29T04:46:56.223256Z","shell.execute_reply.started":"2024-10-29T04:46:56.206605Z","shell.execute_reply":"2024-10-29T04:46:56.222237Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class LandmarkDataset(Dataset):\n    def __init__(self,path):\n        self.root_dir = path\n        self.data = []\n        self.labels = []\n        self.label_to_indices = {}\n        self.min_sequence_length = float('inf')\n\n        # 디렉토리 탐색 및 최소 시퀀스 길이 계산\n        for dance_name in os.listdir(self.root_dir):\n            dance_path = os.path.join(self.root_dir, dance_name)\n            if os.path.isdir(dance_path):\n                for csv_file in os.listdir(dance_path):\n                    # '_F'로 끝나는 파일은 제외\n                    if csv_file.endswith(\".csv\") and not csv_file.endswith(\"_F.csv\"):\n                        file_path = os.path.join(dance_path, csv_file)\n                        self.data.append(file_path)\n                        self.labels.append(dance_name)\n\n                        if dance_name not in self.label_to_indices:\n                            self.label_to_indices[dance_name] = []\n                        self.label_to_indices[dance_name].append(len(self.data) - 1)\n\n                        # 각 CSV 파일의 시퀀스 길이를 체크하여 최소 시퀀스 길이 업데이트\n                        df_angle = make_df_angle(file_path)\n                        sequence_length = len(df_angle)\n                        if sequence_length < self.min_sequence_length:\n                            self.min_sequence_length = sequence_length\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        # 현재 샘플의 라벨 및 파일 경로\n        label = self.labels[idx]\n        file_path1 = self.data[idx]\n\n        # 같은 클래스의 다른 파일을 선택하여 positive 쌍 구성\n        positive_idx = np.random.choice(self.label_to_indices[label])\n        while positive_idx == idx:\n            positive_idx = np.random.choice(self.label_to_indices[label])\n        file_path2 = self.data[positive_idx]\n\n        # 랜덤으로 다른 클래스의 샘플을 선택하여 negative 쌍 구성\n        neg_label = np.random.choice([l for l in self.label_to_indices if l != label])\n        negative_idx = np.random.choice(self.label_to_indices[neg_label])\n        file_path3 = self.data[negative_idx]\n\n        # 각 파일에서 관절 간 각도를 계산\n        angles1 = make_df_angle(file_path1).values[:self.min_sequence_length]\n        angles2 = make_df_angle(file_path2).values[:self.min_sequence_length]\n        angles3 = make_df_angle(file_path3).values[:self.min_sequence_length]\n\n        # numpy array를 torch tensor로 변환\n        angles1 = torch.tensor(angles1, dtype=torch.float32)\n        angles2 = torch.tensor(angles2, dtype=torch.float32)\n        angles3 = torch.tensor(angles3, dtype=torch.float32)\n\n        # Positive 쌍은 (angles1, angles2), negative 쌍은 (angles1, angles3)\n        return angles1, angles2, angles3\n\n    def load_landmark(self, file_path):\n        df = pd.read_csv(file_path)\n        df = df.drop(columns=['filename'])\n        landmarks = df.values[:self.min_sequence_length]\n        return landmarks","metadata":{"execution":{"iopub.status.busy":"2024-10-29T04:46:56.224714Z","iopub.execute_input":"2024-10-29T04:46:56.225034Z","iopub.status.idle":"2024-10-29T04:46:56.240640Z","shell.execute_reply.started":"2024-10-29T04:46:56.225002Z","shell.execute_reply":"2024-10-29T04:46:56.239666Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class TripletContrastiveLoss(nn.Module):\n    def __init__(self, temperature=0.1):\n        super(TripletContrastiveLoss, self).__init__()\n        self.temperature = temperature\n\n    def forward(self, anchor, positive, negative):\n        # Normalize features\n        anchor, positive, negative = F.normalize(anchor, dim=1), F.normalize(positive, dim=1), F.normalize(negative, dim=1)\n        \n        # Calculate similarities\n        pos_sim = torch.exp(torch.sum(anchor * positive, dim=1) / self.temperature)  # Anchor-Positive similarity\n        neg_sim = torch.exp(torch.sum(anchor * negative, dim=1) / self.temperature)  # Anchor-Negative similarity\n\n        # Loss calculation: maximize anchor-positive similarity, minimize anchor-negative similarity\n        loss = -torch.log(pos_sim / (pos_sim + neg_sim)).mean()\n        return loss\n","metadata":{"execution":{"iopub.status.busy":"2024-10-29T04:46:56.241793Z","iopub.execute_input":"2024-10-29T04:46:56.242080Z","iopub.status.idle":"2024-10-29T04:46:56.253602Z","shell.execute_reply.started":"2024-10-29T04:46:56.242051Z","shell.execute_reply":"2024-10-29T04:46:56.252487Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# 데이터셋과 데이터로더\nbatch_size = 8\ntrain_dataset = LandmarkDataset('/kaggle/input/nipa-sample/sample_video')\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n\nval_dataset = LandmarkDataset('/kaggle/input/nipa-val')\nval_dataloader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T04:46:56.254932Z","iopub.execute_input":"2024-10-29T04:46:56.255981Z","iopub.status.idle":"2024-10-29T04:46:58.551933Z","shell.execute_reply.started":"2024-10-29T04:46:56.255930Z","shell.execute_reply":"2024-10-29T04:46:58.550754Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# 하이퍼파라미터\nfeature_dim = len(angle)\noutput_dim = 64\nnum_epochs = 50\nlearning_rate = 0.001\ntemperature = .05\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2024-10-29T04:46:58.553291Z","iopub.execute_input":"2024-10-29T04:46:58.553626Z","iopub.status.idle":"2024-10-29T04:46:58.605019Z","shell.execute_reply.started":"2024-10-29T04:46:58.553590Z","shell.execute_reply":"2024-10-29T04:46:58.603736Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# 모델, 손실 함수, 옵티마이저 초기화\nmodel = skeleton_LSTM(feature_dim, output_dim).to(device)\nclassification = head().to(device)\n\ncriterion1 = TripletContrastiveLoss(temperature=temperature)\ncriterion2 = nn.BCELoss()\ncriterion3 = nn.BCELoss()\n\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\nscheduler = StepLR(optimizer, step_size=10, gamma=0.1)","metadata":{"execution":{"iopub.status.busy":"2024-10-29T04:46:58.608435Z","iopub.execute_input":"2024-10-29T04:46:58.609152Z","iopub.status.idle":"2024-10-29T04:46:59.921893Z","shell.execute_reply.started":"2024-10-29T04:46:58.609117Z","shell.execute_reply":"2024-10-29T04:46:59.921038Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# 학습 루프\n\nbest_val_loss = np.inf\npatience = 10\nepochs_no_improve = 0\n\nfor epoch in range(num_epochs):\n    train_loss = 0.0\n    model.train()\n    classification.train()\n    \n    for batch_idx, (anchor, pos, neg) in enumerate(train_dataloader):\n            \n        optimizer.zero_grad()\n\n        # Positive 쌍과 Negative 쌍을 모델에 각각 통과\n        \n        anchor = anchor.to(device)\n        pos = pos.to(device)\n        neg = neg.to(device)\n        \n        anchor_emb = model(anchor)\n        pos_emb = model(pos)\n        neg_emb = model(neg)\n\n        # Contrastive Loss 계산\n        loss1 = criterion1(anchor_emb, pos_emb, neg_emb)\n        \n        pos_classification = classification(torch.add(anchor_emb,pos_emb))\n        loss2 = criterion2(pos_classification,torch.full((pos_classification.shape[0],1),1.).to(device))\n        \n        neg_classification = classification(torch.add(anchor_emb,neg_emb))\n        loss3 = criterion2(neg_classification,torch.full((pos_classification.shape[0],1),0.).to(device))\n        \n        loss = loss1+loss2+loss3\n        train_loss += loss1.item()\n\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        \n    model.eval()\n    val_loss = 0.0\n    with torch.no_grad():\n        for batch_idx, (anchor, pos, neg) in enumerate(val_dataloader):\n            anchor, pos, neg = anchor.to(device), pos.to(device), neg.to(device)\n\n            anchor_emb = model(anchor)\n            pos_emb = model(pos)\n            neg_emb = model(neg)\n            \n            loss = criterion1(anchor_emb, pos_emb, neg_emb)\n            val_loss += loss.item()\n            \n            \n    # Early Stopping 체크\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        epochs_no_improve = 0  # Improvement이 있으면 카운트 리셋\n        best_model = deepcopy(model)\n    else:\n        epochs_no_improve += 1\n\n    if epochs_no_improve >= patience:\n        print(\"Early stopping triggered!\")\n        break\n\n\n\n#         if batch_idx % 10 == 0:\n#             print(\n#                 f'Epoch [{epoch + 1}/{num_epochs}], Step [{batch_idx + 1}/{len(dataloader)}], Loss: {loss.item():.4f}')\n\n    # 에폭마다 평균 손실을 기록\n    print(f'Epoch [{epoch + 1}/{num_epochs}], Train Average Loss: {train_loss / len(train_dataloader):.4f}, Validation Average Loss: {val_loss:.4f}')\n\nprint(\"Training complete!\")","metadata":{"execution":{"iopub.status.busy":"2024-10-29T04:46:59.923058Z","iopub.execute_input":"2024-10-29T04:46:59.923502Z","iopub.status.idle":"2024-10-29T04:48:28.191608Z","shell.execute_reply.started":"2024-10-29T04:46:59.923461Z","shell.execute_reply":"2024-10-29T04:48:28.190619Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Epoch [1/50], Train Average Loss: 0.3646, Validation Average Loss: 0.3160\nEpoch [2/50], Train Average Loss: 0.1248, Validation Average Loss: 0.2395\nEpoch [3/50], Train Average Loss: 0.1474, Validation Average Loss: 0.4226\nEpoch [4/50], Train Average Loss: 0.0874, Validation Average Loss: 0.4106\nEpoch [5/50], Train Average Loss: 0.0992, Validation Average Loss: 0.2325\nEpoch [6/50], Train Average Loss: 0.0399, Validation Average Loss: 0.4275\nEpoch [7/50], Train Average Loss: 0.0748, Validation Average Loss: 0.3469\nEpoch [8/50], Train Average Loss: 0.0880, Validation Average Loss: 0.1923\nEpoch [9/50], Train Average Loss: 0.0085, Validation Average Loss: 0.3125\nEpoch [10/50], Train Average Loss: 0.0513, Validation Average Loss: 0.4540\nEpoch [11/50], Train Average Loss: 0.0499, Validation Average Loss: 0.2576\nEpoch [12/50], Train Average Loss: 0.0481, Validation Average Loss: 0.2070\nEpoch [13/50], Train Average Loss: 0.0837, Validation Average Loss: 0.5151\nEpoch [14/50], Train Average Loss: 0.0294, Validation Average Loss: 0.4908\nEpoch [15/50], Train Average Loss: 0.1281, Validation Average Loss: 0.2771\nEpoch [16/50], Train Average Loss: 0.0582, Validation Average Loss: 0.2866\nEpoch [17/50], Train Average Loss: 0.0519, Validation Average Loss: 0.3179\nEarly stopping triggered!\nTraining complete!\n","output_type":"stream"}]},{"cell_type":"code","source":"# 유클리디언 거리 계산\nbest_model.eval()\n\norigin_path = '/kaggle/input/gmb-nipa/landmarks/landmarks/기본항목 집합곡 5/landmarks_3d_L.csv'\npos_path = '/kaggle/input/gmb-nipa/landmarks/landmarks/기본항목 집합곡 5/landmarks_3d_P.csv'\nneg_path = '/kaggle/input/gmb-nipa/landmarks/landmarks/Only One (보아)/landmarks_3d_P.csv'\n\norigin = make_df_angle(origin_path)\npos = make_df_angle(pos_path)\nneg = make_df_angle(neg_path)\n\norigin_input = torch.tensor(origin.iloc[:44,].values).unsqueeze(0).to(torch.float32).to(device)\npos_input = torch.tensor(pos.iloc[:44,].values).unsqueeze(0).to(torch.float32).to(device)\nneg_input = torch.tensor(neg.iloc[:44,].values).unsqueeze(0).to(torch.float32).to(device)\n\norigin_emb = best_model(origin_input)\npos_emb = best_model(pos_input)\nneg_emb = best_model(neg_input)\n\npos_dist = torch.pow(F.pairwise_distance(origin_emb, pos_emb), 2)\nneg_dist = torch.pow(F.pairwise_distance(origin_emb, neg_emb), 2)\nprint(pos_dist)\nprint(neg_dist)\nneg_dist/pos_dist","metadata":{"execution":{"iopub.status.busy":"2024-10-29T05:15:39.032184Z","iopub.execute_input":"2024-10-29T05:15:39.033097Z","iopub.status.idle":"2024-10-29T05:15:39.143126Z","shell.execute_reply.started":"2024-10-29T05:15:39.033056Z","shell.execute_reply":"2024-10-29T05:15:39.142256Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"tensor([0.2757], device='cuda:0', grad_fn=<PowBackward0>)\ntensor([12.5613], device='cuda:0', grad_fn=<PowBackward0>)\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:917: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1424.)\n  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n","output_type":"stream"},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"tensor([45.5628], device='cuda:0', grad_fn=<DivBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"# 정규화 후, 유클리디언 거리 계산\nbest_model.eval()\n\norigin = make_df_angle(origin_path)\npos = make_df_angle(pos_path)\nneg = make_df_angle(neg_path)\n\norigin_input = torch.tensor(origin.iloc[:44,].values).unsqueeze(0).to(torch.float32).to(device)\npos_input = torch.tensor(pos.iloc[:44,].values).unsqueeze(0).to(torch.float32).to(device)\nneg_input = torch.tensor(neg.iloc[:44,].values).unsqueeze(0).to(torch.float32).to(device)\n\norigin_emb = F.normalize(best_model(origin_input), dim=1)\npos_emb = F.normalize(best_model(pos_input), dim=1)\nneg_emb = F.normalize(best_model(neg_input), dim=1)\n\npos_dist = torch.pow(F.pairwise_distance(origin_emb, pos_emb), 2)\nneg_dist = torch.pow(F.pairwise_distance(origin_emb, neg_emb), 2)\nprint(pos_dist)\nprint(neg_dist)\nneg_dist/pos_dist","metadata":{"execution":{"iopub.status.busy":"2024-10-29T05:15:39.872206Z","iopub.execute_input":"2024-10-29T05:15:39.872628Z","iopub.status.idle":"2024-10-29T05:15:39.965354Z","shell.execute_reply.started":"2024-10-29T05:15:39.872574Z","shell.execute_reply":"2024-10-29T05:15:39.964425Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"tensor([0.0052], device='cuda:0', grad_fn=<PowBackward0>)\ntensor([0.2902], device='cuda:0', grad_fn=<PowBackward0>)\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:917: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1424.)\n  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"tensor([55.4845], device='cuda:0', grad_fn=<DivBackward0>)"},"metadata":{}}]},{"cell_type":"code","source":"from time import time\n\nmodel.eval()\n\nstart = time()\norigin_path = '/kaggle/input/nipa-sample/sample_video/100 (슈퍼엠)/landmarks_3d_L.csv'\norigin = make_df_angle(origin_path)\norigin_input = torch.tensor(origin.iloc[:44,].values).unsqueeze(0).to(torch.float32).to(device)\n\norigin_emb = F.normalize(best_model(origin_input),dim=1)\ntime()-start","metadata":{"execution":{"iopub.status.busy":"2024-10-29T04:48:28.567366Z","iopub.execute_input":"2024-10-29T04:48:28.567792Z","iopub.status.idle":"2024-10-29T04:48:28.618135Z","shell.execute_reply.started":"2024-10-29T04:48:28.567746Z","shell.execute_reply":"2024-10-29T04:48:28.617002Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/rnn.py:917: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/cudnn/RNN.cpp:1424.)\n  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"0.0372929573059082"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}